{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "hf_dataset_name = \"hotpotqa/hotpot_qa\"\n",
    "directory = \"hotpotqa_hotpot_qa\"\n",
    "# data_dir = \"distractor\"\n",
    "\n",
    "\n",
    "directory = \"rajpurkar_squad_v2\"\n",
    "hf_dataset_name = \"rajpurkar/squad_v2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LakeFSCredentials(endpoint_url='https://lakefs.lmorbits.com', access_key_id='AKIAJKZNY4J56OMMLN2Q', secret_access_key='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', namespace='gs://slmops-dev-data-instructed')\n",
      "Found existing repo qa-manual using storage namespace gs://slmops-dev-data-instructed/lakefs/qa-manual\n",
      "Found existing branch main\n"
     ]
    }
   ],
   "source": [
    "from data.etl.hf_to_lakefs import stream_and_upload_from_hf_to_lakefs,get_info\n",
    "from data.utils.lakefs import LakeFSCredentials\n",
    "from dotenv import load_dotenv\n",
    "from pathlib import Path\n",
    "load_dotenv(Path(\".\").resolve().parent / \"secrets\" / \".env\")\n",
    "\n",
    "credentials = LakeFSCredentials.from_env()\n",
    "\n",
    "project_name = \"qa-manual\"\n",
    "dataset_type = \"raw\"\n",
    "# directory = \"bookcorpus-test-3\"\n",
    "branch_name = \"main\"\n",
    "\n",
    "from data.utils.lakefs import LakeFsDataset,DatasetType\n",
    "lakefs_dataset = LakeFsDataset(credentials=credentials,\n",
    "                               dataset_type=DatasetType(\"raw\"), \n",
    "                               directory=directory, \n",
    "                               project_name=project_name, \n",
    "                              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data.etl.hf_to_lakefs import stream_and_upload_from_hf_to_lakefs\n",
    "from data.utils.hugging_face import get_info\n",
    "\n",
    "info = get_info(hf_dataset_name)\n",
    "splits = info.splits.keys()\n",
    "# for split in splits:\n",
    "#   address = stream_and_upload_from_hf_to_lakefs(hf_dataset_name=hf_dataset_name,dataset=lakefs_dataset,split=split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-02-13 13:35:51.871\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdata.utils.lakefs\u001b[0m:\u001b[36mls\u001b[0m:\u001b[36m223\u001b[0m - \u001b[1mListing files in lakefs://qa-manual/main/raw/rajpurkar_squad_v2/train/**/*.parquet\u001b[0m\n",
      "\u001b[32m2025-02-13 13:36:05.661\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdata.utils.lakefs\u001b[0m:\u001b[36mls\u001b[0m:\u001b[36m223\u001b[0m - \u001b[1mListing files in lakefs://qa-manual/main/raw/rajpurkar_squad_v2/validation/**/*.parquet\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "data_files = lakefs_dataset.load_data_files()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h2>train</h2><table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>context</th>\n",
       "      <th>question</th>\n",
       "      <th>answers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>56be85543aeaaa14008c9063</td>\n",
       "      <td>Beyoncé</td>\n",
       "      <td>Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ bee-YON-say) (born September 4, 1981) is an American singer, songwriter, record producer and actress. Born and raised in Houston, Texas, she performed in various singing and dancing competitions as a child, and rose to fame in the late 1990s as lead singer of R&amp;B girl-group Destiny's Child. Managed by her father, Mathew Knowles, the group became one of the world's best-selling girl groups of all time. Their hiatus saw the release of Beyoncé's debut album, Dangerously in Love (2003), which established her as a solo artist worldwide, earned five Grammy Awards and featured the Billboard Hot 100 number-one singles \"Crazy in Love\" and \"Baby Boy\".</td>\n",
       "      <td>When did Beyonce start becoming popular?</td>\n",
       "      <td>{'text': ['in the late 1990s'], 'answer_start': [269]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>56be85543aeaaa14008c9065</td>\n",
       "      <td>Beyoncé</td>\n",
       "      <td>Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ bee-YON-say) (born September 4, 1981) is an American singer, songwriter, record producer and actress. Born and raised in Houston, Texas, she performed in various singing and dancing competitions as a child, and rose to fame in the late 1990s as lead singer of R&amp;B girl-group Destiny's Child. Managed by her father, Mathew Knowles, the group became one of the world's best-selling girl groups of all time. Their hiatus saw the release of Beyoncé's debut album, Dangerously in Love (2003), which established her as a solo artist worldwide, earned five Grammy Awards and featured the Billboard Hot 100 number-one singles \"Crazy in Love\" and \"Baby Boy\".</td>\n",
       "      <td>What areas did Beyonce compete in when she was growing up?</td>\n",
       "      <td>{'text': ['singing and dancing'], 'answer_start': [207]}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h2>validation</h2><table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>context</th>\n",
       "      <th>question</th>\n",
       "      <th>answers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>56ddde6b9a695914005b9628</td>\n",
       "      <td>Normans</td>\n",
       "      <td>The Normans (Norman: Nourmands; French: Normands; Latin: Normanni) were the people who in the 10th and 11th centuries gave their name to Normandy, a region in France. They were descended from Norse (\"Norman\" comes from \"Norseman\") raiders and pirates from Denmark, Iceland and Norway who, under their leader Rollo, agreed to swear fealty to King Charles III of West Francia. Through generations of assimilation and mixing with the native Frankish and Roman-Gaulish populations, their descendants would gradually merge with the Carolingian-based cultures of West Francia. The distinct cultural and ethnic identity of the Normans emerged initially in the first half of the 10th century, and it continued to evolve over the succeeding centuries.</td>\n",
       "      <td>In what country is Normandy located?</td>\n",
       "      <td>{'text': ['France', 'France', 'France', 'France'], 'answer_start': [159, 159, 159, 159]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>56ddde6b9a695914005b9629</td>\n",
       "      <td>Normans</td>\n",
       "      <td>The Normans (Norman: Nourmands; French: Normands; Latin: Normanni) were the people who in the 10th and 11th centuries gave their name to Normandy, a region in France. They were descended from Norse (\"Norman\" comes from \"Norseman\") raiders and pirates from Denmark, Iceland and Norway who, under their leader Rollo, agreed to swear fealty to King Charles III of West Francia. Through generations of assimilation and mixing with the native Frankish and Roman-Gaulish populations, their descendants would gradually merge with the Carolingian-based cultures of West Francia. The distinct cultural and ethnic identity of the Normans emerged initially in the first half of the 10th century, and it continued to evolve over the succeeding centuries.</td>\n",
       "      <td>When were the Normans in Normandy?</td>\n",
       "      <td>{'text': ['10th and 11th centuries', 'in the 10th and 11th centuries', '10th and 11th centuries', '10th and 11th centuries'], 'answer_start': [94, 87, 94, 94]}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import dask.dataframe as dd\n",
    "from IPython.display import display, HTML\n",
    "ipy_html = lambda df,h : display(HTML(f\"<h2>{h}</h2>\" + df.to_html()))\n",
    "for title, path in data_files.items():\n",
    "    sample_df = dd.read_parquet(path[0], columns=None, \n",
    "                          index=False, \n",
    "                          storage_options=None,\n",
    "                          engine='pyarrow', \n",
    "                          gather_statistics=False, \n",
    "                          split_row_groups=True,\n",
    "                          chunksize=10)\n",
    "    ipy_html(sample_df.head(2),h=title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# how to pipe it \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_df_train = dd.read_parquet(data_files[\"train\"][0], columns=None, \n",
    "                          index=False, \n",
    "                          storage_options=None,\n",
    "                          engine='pyarrow', \n",
    "                          gather_statistics=False, \n",
    "                          split_row_groups=True,\n",
    "                          chunksize=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h2>finalized</h2><table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>conversation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[{'role': 'user', 'content': 'based on the content below answer the question:\n",
       "# content\n",
       "Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ bee-YON-say) (born September 4, 1981) is an American singer, songwriter, record producer and actress. Born and raised in Houston, Texas, she performed in various singing and dancing competitions as a child, and rose to fame in the late 1990s as lead singer of R&amp;B girl-group Destiny's Child. Managed by her father, Mathew Knowles, the group became one of the world's best-selling girl groups of all time. Their hiatus saw the release of Beyoncé's debut album, Dangerously in Love (2003), which established her as a solo artist worldwide, earned five Grammy Awards and featured the Billboard Hot 100 number-one singles \"Crazy in Love\" and \"Baby Boy\".\n",
       "# question\n",
       "question : When did Beyonce start becoming popular?'}, {'role': 'assistant', 'content': 'The answer to your question based on the provided information is: in the late 1990s'}]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[{'role': 'user', 'content': 'based on the content below answer the question:\n",
       "# content\n",
       "Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ bee-YON-say) (born September 4, 1981) is an American singer, songwriter, record producer and actress. Born and raised in Houston, Texas, she performed in various singing and dancing competitions as a child, and rose to fame in the late 1990s as lead singer of R&amp;B girl-group Destiny's Child. Managed by her father, Mathew Knowles, the group became one of the world's best-selling girl groups of all time. Their hiatus saw the release of Beyoncé's debut album, Dangerously in Love (2003), which established her as a solo artist worldwide, earned five Grammy Awards and featured the Billboard Hot 100 number-one singles \"Crazy in Love\" and \"Baby Boy\".\n",
       "# question\n",
       "question : What areas did Beyonce compete in when she was growing up?'}, {'role': 'assistant', 'content': 'The answer to your question based on the provided information is: singing and dancing'}]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h2>finalized_empty_context</h2><table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>conversation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[{'role': 'user', 'content': 'based on the content below answer the question:\n",
       "# content\n",
       "\n",
       "# question\n",
       "question : When did Beyonce start becoming popular?'}, {'role': 'assistant', 'content': 'sorry, I don't know the answer to your question, please provide more information'}]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[{'role': 'user', 'content': 'based on the content below answer the question:\n",
       "# content\n",
       "\n",
       "# question\n",
       "question : What areas did Beyonce compete in when she was growing up?'}, {'role': 'assistant', 'content': 'sorry, I don't know the answer to your question, please provide more information'}]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from data.preprocess.bronze.dask_processes import ExplodeProcess,ExtractNestedProcess,DaskDataProcess, AddConversation \n",
    "from typing import List\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def agregation_function(df: pd.DataFrame) -> List[np.ndarray]:\n",
    "    user_text = (\"based on the content below answer the question:\\n# content\\n\" +\n",
    "                 df[\"context\"].astype(str) +\n",
    "                 \"\\n# question\\nquestion : \" +\n",
    "                 df[\"question\"].astype(str)).to_numpy()\n",
    "    assistant_text = df[\"text\"].astype(str).to_numpy()\n",
    "    assistant_text = np.where((assistant_text != \"\") & (pd.Series(assistant_text).str.len() > 2).to_numpy(), \n",
    "                              \"The answer to your question based on the provided information is: \" + assistant_text, \n",
    "                              assistant_text)\n",
    "    assistant_text = np.where((assistant_text == \" \") | (pd.Series(assistant_text).str.len() <= 2).to_numpy(), \n",
    "                              \"sorry, I don't know the answer to your question\", \n",
    "                              assistant_text)\n",
    "    return user_text, assistant_text\n",
    "\n",
    "def agregation_function_empty_context(df: pd.DataFrame) -> List[np.ndarray]:\n",
    "    # Add new rows with empty context but same question and answer\n",
    "    empty_context_user_text = (\"based on the content below answer the question:\\n# content\\n\" +\n",
    "                               \"\" +\n",
    "                               \"\\n# question\\nquestion : \" +\n",
    "                               df[\"question\"].astype(str)).to_numpy()\n",
    "    empty_context_assistant_text = np.full_like(df[\"question\"].astype(str).to_numpy(), \n",
    "                                                \"sorry, I don't know the answer to your question, please provide more information\")\n",
    "    \n",
    "    return empty_context_user_text, empty_context_assistant_text\n",
    "    \n",
    "    \n",
    "\n",
    "def bronze_pipeline(df: pd.DataFrame , agregation_function) -> pd.DataFrame:\n",
    "    get_text_from_answer = ExtractNestedProcess(new_expected_columns={\"text\": \"object\"}, nested_column=\"answers\")(df)\n",
    "    get_text_from_array_text = ExplodeProcess(new_expected_columns={\"text\": \"string\"})(meta=get_text_from_answer[\"meta\"])\n",
    "    get_human = AddConversation(agregation_function=agregation_function )(meta=get_text_from_array_text[\"meta\"])\n",
    "    new_df = df .map_partitions(**get_text_from_answer)\\\n",
    "                .map_partitions(**get_text_from_array_text)\\\n",
    "                .map_partitions(**get_human)\\\n",
    "                .map_partitions(lambda df: df[[\"conversation\"]])\n",
    "    return new_df\n",
    "\n",
    "ipy_html(bronze_pipeline(sample_df_train, agregation_function).head(2),h=\"finalized\")\n",
    "ipy_html(bronze_pipeline(sample_df_train, agregation_function_empty_context).head(2),h=\"finalized_empty_context\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'user',\n",
       "  'content': 'based on the content below answer the question:\\n# content\\nBeyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ bee-YON-say) (born September 4, 1981) is an American singer, songwriter, record producer and actress. Born and raised in Houston, Texas, she performed in various singing and dancing competitions as a child, and rose to fame in the late 1990s as lead singer of R&B girl-group Destiny\\'s Child. Managed by her father, Mathew Knowles, the group became one of the world\\'s best-selling girl groups of all time. Their hiatus saw the release of Beyoncé\\'s debut album, Dangerously in Love (2003), which established her as a solo artist worldwide, earned five Grammy Awards and featured the Billboard Hot 100 number-one singles \"Crazy in Love\" and \"Baby Boy\".\\n# question\\nquestion : When did Beyonce start becoming popular?'},\n",
       " {'role': 'assistant',\n",
       "  'content': 'the answer to your question based on provided knowledge is in the late 1990s'}]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bronze_pipeline(sample_df_train).head(1).to_dict()[\"conversation\"][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# main process\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from loguru import logger\n",
    "import pyarrow as pa\n",
    "\n",
    "def bronze_pipeline_execute(lakefs_dataset,data_files,agregation_function ,edition:str=None):\n",
    "    \n",
    "    _directory = lakefs_dataset.dataset.get_path()\n",
    "    lakefs_client = lakefs_dataset.lakefs_client\n",
    "    path = f\"{lakefs_client.path}/{_directory}\"\n",
    "    for split in data_files.keys():\n",
    "        logger.info(f\"Processing split: {split} ...\")\n",
    "        ddf = dd.read_parquet(data_files[split], \n",
    "                                columns=[\"question\", \"context\", \"answers\"], \n",
    "                                index=False, \n",
    "                                storage_options=None,\n",
    "                                engine='pyarrow', \n",
    "                                gather_statistics=False, \n",
    "                                split_row_groups=True,\n",
    "                                npartitions=10,\n",
    "                                chunksize=4000,\n",
    "                                )\n",
    "        with lakefs_client.fs.transaction(lakefs_client.repo_manager.repo_name, lakefs_client.branch_manager.current_branch) as tx:\n",
    "                new_df = bronze_pipeline(ddf,agregation_function)\n",
    "                schema = pa.schema([\n",
    "                    (\n",
    "                        \"conversation\",\n",
    "                        pa.list_(\n",
    "                        pa.struct([\n",
    "                            (\"content\", pa.string()),\n",
    "                            (\"role\", pa.string())\n",
    "                        ])\n",
    "                    )\n",
    "                ),\n",
    "                (\"__null_dask_index__\", pa.int64())\n",
    "                ])\n",
    "                new_df.to_parquet(\n",
    "                    path+f\"/{split}\",\n",
    "                    engine=\"pyarrow\",\n",
    "                    write_metadata_file=True,\n",
    "                    filesystem=lakefs_client.fs,\n",
    "                    overwrite=True,\n",
    "                    schema=schema\n",
    "                )\n",
    "                tx.commit(f\"Uploaded dataset bronze from huggingface {hf_dataset_name} to lakefs in {datetime.now()}\")\n",
    "                logger.success(f\"Uploaded dataset bronze from huggingface {hf_dataset_name} to lakefs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-02-05 23:19:34.416\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdata.utils.lakefs\u001b[0m:\u001b[36mls\u001b[0m:\u001b[36m223\u001b[0m - \u001b[1mListing files in lakefs://qa-manual/main/raw/rajpurkar_squad_v2/train/**/*.parquet\u001b[0m\n",
      "\u001b[32m2025-02-05 23:19:48.879\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdata.utils.lakefs\u001b[0m:\u001b[36mls\u001b[0m:\u001b[36m223\u001b[0m - \u001b[1mListing files in lakefs://qa-manual/main/raw/rajpurkar_squad_v2/validation/**/*.parquet\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "data_files = lakefs_dataset.load_data_files()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-02-13 13:36:21.920\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mbronze_pipeline_execute\u001b[0m:\u001b[36m11\u001b[0m - \u001b[1mProcessing split: train ...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LakeFSCredentials(endpoint_url='https://lakefs.lmorbits.com', access_key_id='AKIAJKZNY4J56OMMLN2Q', secret_access_key='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', namespace='gs://slmops-dev-data-instructed')\n",
      "Found existing repo qa-manual using storage namespace gs://slmops-dev-data-instructed/lakefs/qa-manual\n",
      "Found existing branch main\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/parsa/Desk/projects/university/slmops-project/slmops-thesis/lmorbits/.venv/lib/python3.12/site-packages/dask_expr/_collection.py:302: UserWarning: Dask annotations {'retries': 5} detected. Annotations will be ignored when using query-planning.\n",
      "  warnings.warn(\n",
      "No changes to commit on branch 'transaction-591901'.\n",
      "\u001b[32m2025-02-13 13:36:53.729\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mbronze_pipeline_execute\u001b[0m:\u001b[36m45\u001b[0m - \u001b[32m\u001b[1mUploaded dataset bronze from huggingface rajpurkar/squad_v2 to lakefs\u001b[0m\n",
      "\u001b[32m2025-02-13 13:36:53.898\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mbronze_pipeline_execute\u001b[0m:\u001b[36m11\u001b[0m - \u001b[1mProcessing split: validation ...\u001b[0m\n",
      "No changes to commit on branch 'transaction-469163'.\n",
      "\u001b[32m2025-02-13 13:36:59.961\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mbronze_pipeline_execute\u001b[0m:\u001b[36m45\u001b[0m - \u001b[32m\u001b[1mUploaded dataset bronze from huggingface rajpurkar/squad_v2 to lakefs\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "lakefs_dataset = LakeFsDataset(\n",
    "                                credentials=credentials,\n",
    "                                dataset_type=DatasetType(\"bronze\"), \n",
    "                                directory=directory, \n",
    "                                project_name=project_name, \n",
    "                                )\n",
    "\n",
    "bronze_pipeline_execute(lakefs_dataset,data_files,agregation_function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-02-13 13:38:00.033\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mbronze_pipeline_execute\u001b[0m:\u001b[36m11\u001b[0m - \u001b[1mProcessing split: train ...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LakeFSCredentials(endpoint_url='https://lakefs.lmorbits.com', access_key_id='AKIAJKZNY4J56OMMLN2Q', secret_access_key='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', namespace='gs://slmops-dev-data-instructed')\n",
      "Found existing repo qa-manual using storage namespace gs://slmops-dev-data-instructed/lakefs/qa-manual\n",
      "Found existing branch main\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No changes to commit on branch 'transaction-755297'.\n",
      "\u001b[32m2025-02-13 13:38:29.176\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mbronze_pipeline_execute\u001b[0m:\u001b[36m45\u001b[0m - \u001b[32m\u001b[1mUploaded dataset bronze from huggingface rajpurkar/squad_v2 to lakefs\u001b[0m\n",
      "\u001b[32m2025-02-13 13:38:29.356\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mbronze_pipeline_execute\u001b[0m:\u001b[36m11\u001b[0m - \u001b[1mProcessing split: validation ...\u001b[0m\n",
      "No changes to commit on branch 'transaction-023088'.\n",
      "\u001b[32m2025-02-13 13:38:35.038\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mbronze_pipeline_execute\u001b[0m:\u001b[36m45\u001b[0m - \u001b[32m\u001b[1mUploaded dataset bronze from huggingface rajpurkar/squad_v2 to lakefs\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "lakefs_dataset = LakeFsDataset(\n",
    "                                credentials=credentials,\n",
    "                                dataset_type=DatasetType(\"bronze\"), \n",
    "                                directory=directory+\"_empty_context\", \n",
    "                                project_name=project_name, \n",
    "                                )\n",
    "\n",
    "bronze_pipeline_execute(lakefs_dataset,data_files,agregation_function_empty_context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
