steps:
  test_fineruning_with_unsloth:
    enable_cache: false
    parameters:
      from_pretrained:
        model_name: "unsloth/Llama-3.2-1B-Instruct"
        max_seq_length: 2048
        load_in_4bit: True

      peft_adapters:
        r: 16
        target_modules:
          [
            "q_proj",
            "k_proj",
            "v_proj",
            "o_proj",
            "gate_proj",
            "up_proj",
            "down_proj",
          ]
        lora_alpha: 16
        lora_dropout: 0
        bias: "none"
        use_gradient_checkpointing: "unsloth"
        random_state: 3407
        use_rslora: False
        loftq_config: None

      sft_configs:
        max_seq_length: 2048
        dataset_text_field: "text"
        dataset_num_proc: 2
        packing: False
        report_to: "mlflow"

      peft_configs:
        gradient_accumulation_steps: 4
        warmup_steps: 5
        max_steps: 1
        learning_rate: 2e-4
        logging_steps: 1
        optim: "adamw_8bit"
        weight_decay: 0.01
        lr_scheduler_type: "linear"
        seed: 3407
        output_dir: "outputs"

  test_quntization:
    enable_cache: false
    parameters:
      quantization_method: "q5_k_m"

  test_fineruning_dataset_ingestion:
    enable_cache: false
    parameters:
      chat_template: "llama-3.1"
      dataset:
        num_proc: 2
        lakefs:
          directory: "rajpurkar_squad_v2"
          project_name: "qa-manual"
          dataset_type: "bronze"
          branch_name: "main"
          split: "train[:10]"
          # hf:
          #   name: "mlabonne/FineTome-100k"
          #   split: "train"

  test_fineruning_dataset_post_processing:
    enable_cache: false
    parameters:
      chat_template: "llama-3.1"
      column_to_be_used: "conversation"
      chat_mapping:
        role: "role"
        content: "content"
        user: "user"
        assistant: "assistant"
